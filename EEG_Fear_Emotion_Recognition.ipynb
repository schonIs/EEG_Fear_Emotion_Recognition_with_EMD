{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4897707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s1_1', 's1_2', 's1_3', 's2_1', 's2_2', 's2_3', 's3_1', 's3_2', 's3_3', 's4_1', 's4_2', 's4_3', 's5_1', 's5_2', 's5_3']\n",
      "dataの読み込み\n",
      "s1_1.CSV\n",
      "data1に追加\n",
      "s1_2.CSV\n",
      "data2に追加\n",
      "s1_3.CSV\n",
      "data3に追加\n",
      "s2_1.CSV\n",
      "data1に追加\n",
      "s2_2.CSV\n",
      "data2に追加\n",
      "s2_3.CSV\n",
      "data3に追加\n",
      "s3_1.CSV\n",
      "data1に追加\n",
      "s3_2.CSV\n",
      "data2に追加\n",
      "s3_3.CSV\n",
      "data3に追加\n",
      "s4_1.CSV\n",
      "data1に追加\n",
      "s4_2.CSV\n",
      "data2に追加\n",
      "s4_3.CSV\n",
      "data3に追加\n",
      "s5_1.CSV\n",
      "data1に追加\n",
      "s5_2.CSV\n",
      "data2に追加\n",
      "s5_3.CSV\n",
      "data3に追加\n",
      "5\n",
      "8\n",
      "11875\n",
      "9375\n",
      "19375\n",
      "labelの読み込み\n",
      "['s1_1_label', 's1_2_label', 's1_3_label', 's2_1_label', 's2_2_label', 's2_3_label', 's3_1_label', 's3_2_label', 's3_3_label', 's4_1_label', 's4_2_label', 's4_3_label', 's5_1_label', 's5_2_label', 's5_3_label']\n",
      "155\n",
      "325\n",
      "[1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
      " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1]\n",
      "フィルタリング 4-50Hz\n",
      "標準化 Z-score\n",
      "特徴量抽出\n",
      "分類\n",
      "STFTによる分類\n",
      "SVM\n",
      "accuracy: 0.7076923076923076\n",
      "precision: 0.8688654852361845\n",
      "recall: 0.7753433133689047\n",
      "f1: 0.8157289377289377\n",
      "\n",
      "DWTによる分類\n",
      "SVM\n",
      "accuracy: 0.796923076923077\n",
      "precision: 0.8622611118366637\n",
      "recall: 0.9121270431947733\n",
      "f1: 0.882884562884563\n",
      "\n",
      "EMDによる分類\n",
      "SVM\n",
      "accuracy: 0.803076923076923\n",
      "precision: 0.8499573168240921\n",
      "recall: 0.9368760571379188\n",
      "f1: 0.8886869445940059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold,cross_val_score, cross_validate\n",
    "from PyEMD import EMD\n",
    "from scipy import signal\n",
    "from scipy.stats import differential_entropy,zscore\n",
    "\n",
    "#4-50Hzでフィルタリング\n",
    "def filtering(channels, samplerate):   #fsではなくsamplerateとしたのは、阻止域端周波数の変数でfsを使うため\n",
    "    fp = np.array([4, 50])     #通過域端周波数[Hz]※ベクトル\n",
    "    fs = np.array([1, 60])      #阻止域端周波数[Hz]※ベクトル\n",
    "    gpass = 1                       #通過域端最大損失[dB]\n",
    "    gstop = 10                      #阻止域端最小損失[dB]\n",
    "    nyquist = samplerate / 2                           #ナイキスト周波数\n",
    "    wp = fp / nyquist                                  #ナイキスト周波数で通過域端周波数を正規化\n",
    "    ws = fs / nyquist                                  #ナイキスト周波数で阻止域端周波数を正規化\n",
    "    N, Wn = signal.buttord(wp, ws, gpass, gstop)  #オーダーとバターワースの正規化周波数を計算\n",
    "    b, a = signal.butter(N, Wn, \"band\")           #フィルタ伝達関数の分子と分母を計算\n",
    "    \n",
    "    filtered_channels = []\n",
    "    \n",
    "    for channel in range(len(channels)):\n",
    "        y = signal.filtfilt(b, a, channels[channel])                  #信号に対してフィルタをかける\n",
    "        filtered_channels.append(y)\n",
    "    \n",
    "    filtered_channels = np.array(filtered_channels)\n",
    "    \n",
    "    #return filtered_channels\n",
    "    return channels\n",
    "\n",
    "#標準化:平均0, 標準偏差1\n",
    "def scaling(channels):\n",
    "    zscore_chennels = []\n",
    "    for channel in range(len(channels)):\n",
    "        zscore_chennels.append(zscore(channels[channel]))\n",
    "    zscore_chennels = np.array(zscore_chennels)\n",
    "    \n",
    "    return zscore_chennels\n",
    "\n",
    "\n",
    "def extract_features_by_STFT(channels,fs):\n",
    "    window = np.hanning(625) #ハニング窓\n",
    "    features=[]\n",
    "    \n",
    "    for n in range(len(channels[0])//625):\n",
    "        features.append([])\n",
    "\n",
    "    for channel in range(len(channels)):\n",
    "        start = 0\n",
    "        end = 625\n",
    "        # n: 全サンプル数/5sのサンプル数(125Hz*5=625)\n",
    "        for n in range(len(channels[channel])//625):\n",
    "            signal_sample = np.array(channels[channel][start:end])\n",
    "            \n",
    "            y_fft = np.fft.fft(window * signal_sample) # Fast Fourier Transform\n",
    "            amp = np.abs(y_fft/(len(signal_sample)/2)) # Amplitude\n",
    "            flist = np.fft.fftfreq(len(signal_sample), d=1.0/fs) # Frequency List\n",
    "            amp = amp[1:len(amp)//2] # ナイキスト周波数を考慮\n",
    "            flist = flist[1:len(flist)//2]\n",
    "            power = amp**2 # パワースペクトル\n",
    "            \n",
    "            theta = np.sum(power[4 *  int((len(flist)+1)//62.5) -1:7 *  int((len(flist)+1)//62.5) ]) #theta\n",
    "            alpha = np.sum(power[8 *  int((len(flist)+1)//62.5) -1:13 *  int((len(flist)+1)//62.5) ]) #alpha\n",
    "            beta = np.sum(power[13 *  int((len(flist)+1)//62.5) -1:30 *  int((len(flist)+1)//62.5) ]) #beta\n",
    "            beta_alpha_ratio = beta/alpha\n",
    "            theta_beta_ratio = theta/beta\n",
    "            \n",
    "            alpha_de = differential_entropy(amp[8 *  int((len(flist)+1)//62.5) -1:13 *  int((len(flist)+1)//62.5) ])\n",
    "            beta_de = differential_entropy(amp[13 *  int((len(flist)+1)//62.5) -1:30 *  int((len(flist)+1)//62.5) ])\n",
    "            gamma_de = differential_entropy(amp[30 *  int((len(flist)+1)//62.5) -1:50 *  int((len(flist)+1)//62.5) ])\n",
    "            alpha_mean = np.mean(amp)\n",
    "            beta_mean = np.mean(amp)\n",
    "            gamma_mean = np.mean(amp)\n",
    "            \n",
    "            features[n].append(alpha_de) #差分エントロピー\n",
    "            features[n].append(alpha_mean) #平均\n",
    "            features[n].append(beta_de)\n",
    "            features[n].append(beta_mean)\n",
    "            features[n].append(gamma_de)\n",
    "            features[n].append(gamma_mean)\n",
    "            \n",
    "            features[n].append(beta_alpha_ratio)\n",
    "            features[n].append(theta_beta_ratio)\n",
    "            \n",
    "            start += 625\n",
    "            end += 625\n",
    "        \n",
    "    features = np.array(features)\n",
    "         \n",
    "    return features\n",
    "\n",
    "def extract_features_by_DWT(channels,fs):\n",
    "    features=[]\n",
    "    \n",
    "    for n in range(len(channels[0])//625):\n",
    "        features.append([])\n",
    "\n",
    "    for channel in range(len(channels)):\n",
    "        start = 0\n",
    "        end = 625\n",
    "        # n: 全サンプル数/5sのサンプル数(125Hz*5=625)\n",
    "        for n in range(len(channels[channel])//625):\n",
    "            signal_sample = np.array(channels[channel][start:end])\n",
    "            #500Hzのサンプリング周波数なので, 250Hzがナイキストである. よって、levelは5?\n",
    "            #125Hzには4??\n",
    "            coeffs = pywt.wavedec(signal_sample,'db4',level = 5)\n",
    "            #0-8 8-16 16-31 31-63 63-125 125-250\n",
    "            # 1   2     3     4     5       6\n",
    "            for i in range(1,4):   #(1,4)\n",
    "                #plt.plot(coeffs[i+1])\n",
    "                #plt.title(\"coefficient\"+str(i+1))\n",
    "                #plt.show()\n",
    "                \n",
    "                y_fft = np.fft.fft(coeffs[i]) # Fast Fourier Transform\n",
    "                amp = np.abs(y_fft/(len(coeffs[i])/2)) # Amplitude\n",
    "                flist = np.fft.fftfreq(len(coeffs[i]), d=1.0/fs) # Frequency List\n",
    "                amp = amp[1:len(amp)//2] # ナイキスト周波数を考慮\n",
    "                flist = flist[1:len(flist)//2]\n",
    "                \n",
    "                de = differential_entropy(amp)\n",
    "                mean = np.mean(amp)\n",
    "                features[n].append(mean)\n",
    "                features[n].append(de)\n",
    "        \n",
    "            start += 625\n",
    "            end += 625\n",
    "        \n",
    "    features = np.array(features)\n",
    "        \n",
    "    return features\n",
    "\n",
    "#DEを特徴量\n",
    "def extract_features_by_EMD(channels,fs):\n",
    "    features=[]\n",
    "    \n",
    "    for n in range(len(channels[0])//625):\n",
    "        features.append([])\n",
    "\n",
    "    for channel in range(len(channels)):\n",
    "        start = 0\n",
    "        end = 625\n",
    "        # n: 全サンプル数/5sのサンプル数(125Hz*5=625)\n",
    "        for n in range(len(channels[channel])//625):\n",
    "            signal_sample = np.array(channels[channel][start:end])          \n",
    "            IMFs = EMD().emd(signal_sample, None)\n",
    "            \n",
    "            for i in range(5):\n",
    "                #最初の4つのIMFでDEを計算する(5だと段違いで精度高いけども)\n",
    "                \n",
    "                y_fft = np.fft.fft(IMFs[i]) # Fast Fourier Transform\n",
    "                amp = np.abs(y_fft/(len(IMFs[i])/2)) # Amplitude\n",
    "                flist = np.fft.fftfreq(len(IMFs[i]), d=1.0/fs) # Frequency List\n",
    "                amp = amp[1:len(amp)//2] # ナイキスト周波数を考慮\n",
    "                flist = flist[1:len(flist)//2]\n",
    "                \n",
    "                de = differential_entropy(amp)\n",
    "                mean = np.mean(amp)\n",
    "                features[n].append(mean)\n",
    "                features[n].append(de)\n",
    "                \n",
    "            start += 625\n",
    "            end += 625\n",
    "\n",
    "    features = np.array(features)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def print_to_file(accuracy, precision, recall, f1, analysis, classification):\n",
    "    with open('result_'+analysis+'_'+classification+'.txt', 'w+') as file:\n",
    "        text = \"Accuracy: \" + str(accuracy) + \"\\n\"\n",
    "        text += \"Precision: \" + str(precision)+ \"\\n\"\n",
    "        text += \"Recall: \" + str(recall)+ \"\\n\"\n",
    "        text += \"F1: \" + str(f1)+ \"\\n\"\n",
    "        file.write(text)\n",
    "            \n",
    "\n",
    "class Main:\n",
    "    files = []\n",
    "    for subject in range(1,6): #被験者5人\n",
    "        for movie in range(1,4): #動画3つ\n",
    "            s = 's'\n",
    "            s += str(subject)\n",
    "            s += '_'\n",
    "            s += str(movie)\n",
    "            files.append(s)\n",
    "    print(files)\n",
    "    \n",
    "    # dataの読み込み\n",
    "    fs = 125 #サンプリング周波数は500Hzが125Hzにダウンサンプリングされている\n",
    "    print(\"dataの読み込み\")\n",
    "    data1=[]  #動画1の読み込み\n",
    "    data2=[]  #動画2の読み込み\n",
    "    data3=[]  #動画3の読み込み\n",
    "    for n,file in enumerate(files):\n",
    "        filename = file+'.CSV'\n",
    "        df = pd.read_csv(filename, header=None)  #csvファイルの読み込み\n",
    "        if (n+1)%3==1:\n",
    "            print(filename)\n",
    "            print(\"data1に追加\")\n",
    "            data1.append(df.iloc[:,0:8].values.T)  #iloc[全部の行, 1列～8列]を取り出してdata1へ\n",
    "        elif (n+1)%3==2:\n",
    "            print(filename)\n",
    "            print(\"data2に追加\")\n",
    "            data2.append(df.iloc[:,0:8].values.T)  #iloc[全部の行, 1列～8列]を取り出してdata2へ\n",
    "        elif (n+1)%3==0:\n",
    "            print(filename)\n",
    "            print(\"data3に追加\")\n",
    "            data3.append(df.iloc[:,0:8].values.T)  #iloc[全部の行, 1列～8列]を取り出してdata3へ\n",
    "\n",
    "    #5人*8チャンネル×11875点(95秒)\n",
    "    data1 = np.array(data1)\n",
    "    data2 = np.array(data2)\n",
    "    data3 = np.array(data3)\n",
    "    print(len(data1))\n",
    "    print(len(data1[0]))\n",
    "    print(len(data1[0][0]))\n",
    "    print(len(data2[0][0]))\n",
    "    print(len(data3[0][0]))\n",
    "    \n",
    "    #labelの読み込み\n",
    "    print(\"labelの読み込み\")\n",
    "    files_label = []\n",
    "    for subject in range(1,6): #被験者5人\n",
    "        for movie in range(1,4): #動画3つ\n",
    "            s = 's'\n",
    "            s += str(subject)\n",
    "            s += '_'\n",
    "            s += str(movie)\n",
    "            s += '_label'\n",
    "            files_label.append(s)\n",
    "    print(files_label)\n",
    "    \n",
    "    labels1 = []\n",
    "    labels2 = []\n",
    "    labels3 = []\n",
    "    for n,file in enumerate(files_label):\n",
    "        filename = file+'.csv'\n",
    "        df = pd.read_csv(filename, header=None)  #csvファイルの読み込み\n",
    "        if (n+1)%3==1:\n",
    "            labels1.append(df.iloc[:,4].values.T)\n",
    "            #labels1 = np.array(df.iloc[:,0].values.T)  #labels1へ\n",
    "        elif (n+1)%3==2:\n",
    "            labels2.append(df.iloc[:,4].values.T)\n",
    "            #labels2l = np.array(df.iloc[:,0].values.T)  #labels2へ\n",
    "        elif (n+1)%3==0:\n",
    "            labels3.append(df.iloc[:,4].values.T)\n",
    "            #labels3 = np.array(df.iloc[:,0].values.T)  #labels3へ\n",
    "    \n",
    "    #arrayにしてから1次元に変換\n",
    "    labels1 = np.array(labels1)\n",
    "    labels1 = labels1.ravel()\n",
    "    labels2 = np.array(labels2)\n",
    "    labels2 = labels2.ravel()\n",
    "    labels3 = np.array(labels3)\n",
    "    labels3 = labels3.ravel()\n",
    "    print(len(labels3))\n",
    "    \n",
    "    labels = []\n",
    "    for i in range(325):#325\n",
    "        labels.append([])\n",
    "        \n",
    "    for n,label in enumerate(labels1):\n",
    "        labels[n].append(label)\n",
    "    for n,label in enumerate(labels2):\n",
    "        labels[n+95].append(label)  #19*~  95\n",
    "    for n,label in enumerate(labels3):\n",
    "        labels[n+170].append(label)  #34*~  170\n",
    "    \n",
    "    labels = np.array(labels)\n",
    "    labels = labels.ravel()  #次元を1次元に\n",
    "    print(len(labels))\n",
    "    print(labels)\n",
    "\n",
    "    #Filtering 動画ごとに\n",
    "    print(\"フィルタリング 4-50Hz\")\n",
    "    filtered_data1 = []\n",
    "    for subject in range(len(data1)):\n",
    "        #各被験者のデータごとにフィルタリング\n",
    "        filtered_data1.append(filtering(data1[subject],samplerate=fs))\n",
    "\n",
    "    filtered_data2 = []\n",
    "    for subject in range(len(data2)):\n",
    "        #各被験者のデータごとにフィルタリング\n",
    "        filtered_data2.append(filtering(data2[subject],samplerate=fs))\n",
    "\n",
    "    filtered_data3 = []\n",
    "    for subject in range(len(data3)):\n",
    "        #各被験者のデータごとにフィルタリング\n",
    "        filtered_data3.append(filtering(data3[subject],samplerate=fs))\n",
    "    \n",
    "    filtered_data1 = np.array(filtered_data1)\n",
    "    filtered_data2 = np.array(filtered_data2)\n",
    "    filtered_data3 = np.array(filtered_data3)\n",
    "    \n",
    "    #Scaling 標準化\n",
    "    print(\"標準化 Z-score\")\n",
    "    stand_data1=[]\n",
    "    for subject in range(len(filtered_data1)):\n",
    "        stand_data1.append(scaling(filtered_data1))\n",
    "    stand_data2=[]\n",
    "    for subject in range(len(filtered_data2)):\n",
    "        stand_data2.append(scaling(filtered_data2))\n",
    "    stand_data3=[]\n",
    "    for subject in range(len(filtered_data3)):\n",
    "        stand_data3.append(scaling(filtered_data3))\n",
    "        \n",
    "    stand_data1=np.array(stand_data1)\n",
    "    stand_data2=np.array(stand_data2)\n",
    "    stand_data3=np.array(stand_data3)\n",
    "    #stand_dataたちは使ってません。\n",
    "        \n",
    "    \n",
    "    #Extracting features 動画ごとに\n",
    "    print(\"特徴量抽出\")\n",
    "    features_data1_STFT = []\n",
    "    features_data1_DWT = []\n",
    "    features_data1_EMD = []\n",
    "    for subject in range(len(filtered_data1)):\n",
    "        features_data1_STFT.append(extract_features_by_STFT(filtered_data1[subject],fs))\n",
    "        features_data1_DWT.append(extract_features_by_DWT(filtered_data1[subject],fs))\n",
    "        features_data1_EMD.append(extract_features_by_EMD(filtered_data1[subject],fs))\n",
    "    \n",
    "    features_data2_STFT = []\n",
    "    features_data2_DWT = []\n",
    "    features_data2_EMD = []\n",
    "    for subject in range(len(filtered_data2)):\n",
    "        features_data2_STFT.append(extract_features_by_STFT(filtered_data2[subject],fs))\n",
    "        features_data2_DWT.append(extract_features_by_DWT(filtered_data2[subject],fs))\n",
    "        features_data2_EMD.append(extract_features_by_EMD(filtered_data2[subject],fs))\n",
    "    \n",
    "    features_data3_STFT = []\n",
    "    features_data3_DWT = []\n",
    "    features_data3_EMD = []\n",
    "    for subject in range(len(filtered_data3)):\n",
    "        features_data3_STFT.append(extract_features_by_STFT(filtered_data3[subject],fs))\n",
    "        features_data3_DWT.append(extract_features_by_DWT(filtered_data3[subject],fs))\n",
    "        features_data3_EMD.append(extract_features_by_EMD(filtered_data3[subject],fs))\n",
    "\n",
    "    #Making Training data\n",
    "    X_STFT = [] # STFT用\n",
    "    for subject in range(len(features_data1_STFT)):\n",
    "        for f in features_data1_STFT[subject]:  #セグメントごとに追加\n",
    "            X_STFT.append(f)\n",
    "    for subject in range(len(features_data2_STFT)):\n",
    "        for f in features_data2_STFT[subject]:\n",
    "            X_STFT.append(f)\n",
    "    for subject in range(len(features_data3_STFT)):\n",
    "        for f in features_data3_STFT[subject]:\n",
    "            X_STFT.append(f)\n",
    "    X_STFT = np.array(X_STFT)\n",
    "    \n",
    "    X_DWT = [] # DWT用\n",
    "    for subject in range(len(features_data1_DWT)):\n",
    "        for f in features_data1_DWT[subject]:  #セグメントごとに追加\n",
    "            X_DWT.append(f)\n",
    "    for subject in range(len(features_data2_DWT)):\n",
    "        for f in features_data2_DWT[subject]:\n",
    "            X_DWT.append(f)\n",
    "    for subject in range(len(features_data3_DWT)):\n",
    "        for f in features_data3_DWT[subject]:\n",
    "            X_DWT.append(f)\n",
    "    X_DWT = np.array(X_DWT)\n",
    "    \n",
    "    X_EMD = [] # EMD用\n",
    "    for subject in range(len(features_data1_EMD)):\n",
    "        for f in features_data1_EMD[subject]:  #セグメントごとに追加\n",
    "            X_EMD.append(f)\n",
    "    for subject in range(len(features_data2_EMD)):\n",
    "        for f in features_data2_EMD[subject]:\n",
    "            X_EMD.append(f)\n",
    "    for subject in range(len(features_data3_EMD)):\n",
    "        for f in features_data3_EMD[subject]:\n",
    "            X_EMD.append(f)\n",
    "    X_EMD = np.array(X_EMD)\n",
    "        \n",
    "    # classification by SVM\n",
    "    print(\"分類\")\n",
    "    #5 fold cross validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=2)#split5\n",
    "    \n",
    "    scoring = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': 'precision',\n",
    "        'recall' :'recall',\n",
    "        'f1': 'f1',\n",
    "    } \n",
    "    \n",
    "    \"\"\"\n",
    "    STFT\n",
    "    \"\"\"\n",
    "    print(\"STFTによる分類\")\n",
    "    svm = SVC(kernel='rbf', C=1, gamma=0.1, class_weight='balanced')\n",
    "    scores = cross_validate(svm, X_STFT, labels, cv=kf, scoring=scoring)\n",
    "    print(\"SVM\")\n",
    "    print(\"accuracy: {}\".format(np.mean(scores['test_accuracy'])))\n",
    "    print(\"precision: {}\".format(np.mean(scores['test_precision'])))\n",
    "    print(\"recall: {}\".format(np.mean(scores['test_recall'])))\n",
    "    print(\"f1: {}\\n\".format(np.mean(scores['test_f1'])))\n",
    "    print_to_file(np.mean(scores['test_accuracy']), np.mean(scores['test_precision']), np.mean(scores['test_recall']),\n",
    "                  np.mean(scores['test_f1']), \"STFT\", \"SVM\")\n",
    "    \n",
    "    \"\"\"\n",
    "    DWT\n",
    "    \"\"\"\n",
    "    print(\"DWTによる分類\")\n",
    "    svm = SVC(kernel='rbf', C=1, gamma=0.1, class_weight='balanced')\n",
    "    scores = cross_validate(svm, X_DWT, labels, cv=kf, scoring=scoring)\n",
    "    print(\"SVM\")\n",
    "    print(\"accuracy: {}\".format(np.mean(scores['test_accuracy'])))\n",
    "    print(\"precision: {}\".format(np.mean(scores['test_precision'])))\n",
    "    print(\"recall: {}\".format(np.mean(scores['test_recall'])))\n",
    "    print(\"f1: {}\\n\".format(np.mean(scores['test_f1'])))\n",
    "    print_to_file(np.mean(scores['test_accuracy']), np.mean(scores['test_precision']), np.mean(scores['test_recall']),\n",
    "                  np.mean(scores['test_f1']), \"DWT\", \"SVM\")\n",
    "    \n",
    "    \"\"\"\n",
    "    EMD\n",
    "    \"\"\"\n",
    "    print(\"EMDによる分類\")\n",
    "    svm = SVC(kernel='rbf', C=1, gamma=0.1, class_weight='balanced')\n",
    "    scores = cross_validate(svm, X_EMD, labels, cv=kf, scoring=scoring)\n",
    "    print(\"SVM\")\n",
    "    print(\"accuracy: {}\".format(np.mean(scores['test_accuracy'])))\n",
    "    print(\"precision: {}\".format(np.mean(scores['test_precision'])))\n",
    "    print(\"recall: {}\".format(np.mean(scores['test_recall'])))\n",
    "    print(\"f1: {}\\n\".format(np.mean(scores['test_f1'])))\n",
    "    print_to_file(np.mean(scores['test_accuracy']), np.mean(scores['test_precision']), np.mean(scores['test_recall']),\n",
    "                  np.mean(scores['test_f1']), \"EMD\", \"SVM\")\n",
    "    \"\"\"\n",
    "    # test\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    svm_test_STFT = SVC(kernel='rbf', C=1, gamma=0.1, class_weight='balanced')\n",
    "    svm_test_STFT.fit(X_STFT[:294], labels[:294])\n",
    "    y_pred = svm_test_STFT.predict(X_STFT[294:325])\n",
    "    accuracy_score(labels[294:325], y_pred)\n",
    "    print(\"Predicted values: \" + str(y_pred))\n",
    "    print(\"Real values:      \" + str(labels[294:325]))\n",
    "    print(str(accuracy_score(labels[294:325], y_pred)))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    svm_test_EMD = SVC(kernel='rbf', C=1, gamma=0.1, class_weight='balanced')\n",
    "    svm_test_EMD.fit(X_EMD[:294], labels[:294])\n",
    "    y_pred = svm_test_EMD.predict(X_EMD[294:325])\n",
    "    accuracy_score(labels[294:325], y_pred)\n",
    "    print(\"Predicted values: \" + str(y_pred))\n",
    "    print(\"Real values:      \" + str(labels[294:325]))\n",
    "    print(str(accuracy_score(labels[294:325], y_pred)))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9594fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b7161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
